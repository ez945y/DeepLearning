{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c90ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "data_path = '../data-unversioned/p1ch7'\n",
    "cifar10 = datasets.CIFAR10(data_path, train = True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a941338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.cifar.CIFAR10,\n",
       " torchvision.datasets.vision.VisionDataset,\n",
       " torch.utils.data.dataset.Dataset,\n",
       " typing.Generic,\n",
       " object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar10).__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ae615a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13cc019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32 at 0x2006BD877F0>, 1, 'automobile')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "img, label = cifar10[99]\n",
    "img, label, class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8ab9ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8388\\4248077660.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2646\u001b[0m         \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2647\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m   2648\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2649\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5486\u001b[0m                               **kwargs)\n\u001b[0;32m   5487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5488\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5489\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    714\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    715\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 716\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (3, 32, 32) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e8f2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AutoAugment',\n",
       " 'AutoAugmentPolicy',\n",
       " 'CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'FiveCrop',\n",
       " 'GaussianBlur',\n",
       " 'Grayscale',\n",
       " 'InterpolationMode',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandAugment',\n",
       " 'RandomAdjustSharpness',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomAutocontrast',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomEqualize',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomInvert',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomPosterize',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSolarize',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " 'TrivialAugmentWide',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'autoaugment',\n",
       " 'functional',\n",
       " 'functional_pil',\n",
       " 'functional_tensor',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3909eba8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8388\\2113446133.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mto_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mF_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"pic should be PIL Image or ndarray. Got {type(pic)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd9181a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10(data_path, train = True, download = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e62e1a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t, _ = tensor_cifar10[99]\n",
    "type(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab0e121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]), torch.float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.shape, img_t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb272724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.min(), img_t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca7848d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfE0lEQVR4nO2de4xd13Xev3Xf8+Rwhq8RRYmiKIt6WK/SqlyrhqwgjuoGkY0Wip0mEALDDIoYqFHnD8EFagfoH0lRy3XTwgUdK1ECx28bFmLDsaIocQw/JEqmSEqUZIqkxOcMyXnP3Pdd/eNeFpSyvz1DcuYOo/39AIJ39rr7nHX2Peuce/d31trm7hBCvP3JrLYDQojuoGAXIhEU7EIkgoJdiERQsAuRCAp2IRIhdzmdzewBAJ8HkAXwp+7+R7H35/M5L5XyQVur1aT9vNViDtA+mehljPeL2dzDfkTcQEzaNMtegheARXaYzYXHN5sNtwNAeWEusjcy9gB6Sj3U1tfbH2xfWJinfer1MrVlIsecz/LTOJMrBtt7+8PtANCMnIvlGvc/n+MnXT4X+awz4XMkl+XbW1gI95mcLGN+vhYcrEsOdmufqf8HwK8COA7gWTN7wt1fYn1KpTzu2rk9aJubmaD7atSqwfZsng9Gb28kaFuRw85wW60a9iMf2VyzXqO2fG6A2iwS7vkCP1HXjmwMtg8NbqJ99u//MbXBuf833Xgrtd1z+78Ktj/3wjO0z+mTB6itt8gvVlcNrKe2vnXXBdtve8822memOkVtB49w/zdt5J/nxhFuK/aGLy5DkQvSvr2NYPv/+pOf0D6X8zX+bgCH3P2wu9cAfBXAg5exPSHECnI5wb4ZwLEL/j7eaRNCXIFc1m/2pWBmuwDsAoBi5KuYEGJluZw7+wkAWy74++pO25tw993uvtPdd+bzfJJCCLGyXE6wPwvgBjO7zswKAD4M4InlcUsIsdxc8td4d2+Y2ccB/A3a0ttj7v5itJM5zMiMduSmnymUgu25YuRaFdGuzPnOKvNh/wCgRWSo2Oy45SLSWy48o9qmQC2TM9PUdnZyMtheLu/lfkTktb6e8NgDwNjkOWp78qd/F2xvGZe1ZmoVauuJ+DFT4f2GBsMSYE8xrAoBwJZRPnM+NX2S2oZHuB8Dg/ycW6iG5by5BX4OlHrDP4kzGX7iX9Zvdnf/PoDvX842hBDdQU/QCZEICnYhEkHBLkQiKNiFSAQFuxCJsOJP0F2IO1BvhqWonoE+2q9CcjFaTS51NBv8ab1qhctr/f1hqQYAvD4T3hfLygPQMn49LeYi+mCGZ6LlS1yGqs2GM8eKJS7jwLgE6MYTYU6Ov0FteZIdVF3g0lshUvu0p8D9qGb4NmtHw8k1C7V/8vzX/6dUXEttV225mtoqszQHDGOz3MdsIXwezDrPsBufCJ/D9Qb/LHVnFyIRFOxCJIKCXYhEULALkQgKdiESoauz8RkDiiR5ZXpmgfYzD88kx5I0YokT8+WLrzMHAOVaeLq4tz8y093ks6PlBV5zrV7hfuRKdWozC/fLRWqgeeyaT9QTAOjJc8WjXg+fWpkm96PlXF1ZiCQo9fTwxJXyQjgxaOwM39fcwjFqGxy+n9pKvbz010xljNoq5fAYN8EViLPT4fFoNPl5ozu7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEqGr0luz1cI8SdSocyUEQ2vCMlqlzOW6ZiQhYHqaSxozM+FkFwAYIat69HOVD9MzEeltjsta+QL/aBbmI4krRDp059f1apknabTqkRp6WS7zFPPhbVqJb6/B3WjrtoTeLLeVwysh4cwkTzIpFiP17qZ43b1JIocBwPhZbhscDH82kVMY5fnwcXkzsiQa35wQ4u2Egl2IRFCwC5EICnYhEkHBLkQiKNiFSITLkt7M7CiAWQBNAA133xl7f8YMhVI466lU4hlUc2S5o3pEq6nV+KFVq7y+2/AI92NwMNw+dpJvr9biGWpFMhYAEEkoQy4yVpWFsPRSqXA/SsXIWEUyr7zFtSGW3JaP1ORr1iOyUUSKLJd4v6n5sP+NZqQm3Fo+vqfGjlNbrcWzGCsRbblSDkt9zUgGW7ka9j/WZzl09ve5+9ll2I4QYgXR13ghEuFyg90B/NDMnjOzXcvhkBBiZbjcr/H3uvsJM9sA4Ekze9ndf3ThGzoXgV0AUCxG1mUWQqwol3Vnd/cTnf/HAXwHwN2B9+x2953uvjMfW4RdCLGiXHKwm1mfmQ2cfw3g/QDCy28IIVady/kavxHAd8zs/Hb+yt1/EOvQagELc2FpIJPlskWOeJnN80KPHpEgtt80RG0DfXxIZs6G5avm2kjWVSSjLBMpAlkj0goADA3zfmvXhWWjuRnuY7XMx2p4I1+Wq2hcopqZC0tedcSWQeLbK0dk1oUWH48GWSKsWeaS4qzxfVVrXG5cOzxMbZG6nVjwsHRbzPHzu9maDba7c98vOdjd/TCA2y+1vxCiu0h6EyIRFOxCJIKCXYhEULALkQgKdiESobtrvWWAwd7w9SUbyWqanw3LJPlcpGBjicsWLVKEEADqxrPDvBCWqEZINhwAnDzG98VkSABoOvcjV+JjtXYwLF81I+vbFSLb642NY4v73yLZZkPreDHHMq8BidlpnjU2cTacFQkA/b1h/3OkHQCaLX5e1avcNj0dlsOAeKZliaxLmB/in9lVm9eH+xR4QUzd2YVIBAW7EImgYBciERTsQiSCgl2IROjqbLwDqLXCM4yzY3y2cu1weLq71eTLP9UtMsPcy5fimYvMtjZr4RnmUoHP7A4McNuaPp7AMTHFZ7qnJyKz+NWwjznw4+qP+FhZ4GNVI/sCgMGhYrC9wLKaABQjqsa5MT4z3dPPx3G+Gj5HihEFoho7Bxa4StLb5OOYK8aSpcJj7JGkoTKRLuqRRB3d2YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIXZXeWs0WZufCkkGzyWWceSJNzExxWaiY5xJJNstrnWUzkSWISHutFqn7lee2ngKXeMp1fh12j8mDYVmuFTnmygRPMilk+SmSz/ZwPzwsecXGvlbmx5yxyBJP0/zcWTsSlgDLVX7uVGt8fEeGYok8XPZaqHJbi5wi05Pcj9GNa4PtzlVZ3dmFSAUFuxCJoGAXIhEU7EIkgoJdiERQsAuRCItKb2b2GIBfBzDu7rd22oYBfA3AVgBHATzk7pOLbSuTyWCgFJZrxmb58k8L5ZlguzvPdvJmZLmgWX6Nu+6mfmqrkFJnU3NcxvFInbZqg9tKa/ix9fVH5Kvp8DanznEfW1ku8bSMS0YObusdCo9xK8NlsjXre6ntuiK3TU9x6bBRJz5G1mMaWMPPj8FIXTi0eDi9cZJnaA4Ph5fYGoxkI9Zq4XjxiPa2lDv7nwN44C1tjwB4yt1vAPBU528hxBXMosHeWW994i3NDwJ4vPP6cQAfXF63hBDLzaX+Zt/o7qc6r0+jvaKrEOIK5rIfl3V3NzP6A8jMdgHYBQCFAv8dKoRYWS71zj5mZqMA0Pl/nL3R3Xe7+05335nPK9iFWC0uNdifAPBw5/XDAL67PO4IIVaKpUhvXwFwH4B1ZnYcwKcB/BGAr5vZRwG8DuChpewskzH0kqVuMpG7foYsx1PiCUhYt5Eb123kh91ocolqZi4s59W4qoJGnUuAw1fxrLGhYb7NapVvc5ZkCDYikoxX+TV/03Yu/9Qr3I+shW3ZHO+DDJfycgVu6+vnn+eZ8bDU11eMZPNFikNOz3E/Bvr4WF3VxyXdSSLdDkbk11IpbMtEsjYXDXZ3/wgx/cpifYUQVw56gk6IRFCwC5EICnYhEkHBLkQiKNiFSISuFpysVut49fDxsNF4JlepJ3xNWj/KpauRkVj2D894atT4kPT1h2WNniL3/Y3XudRkkWvt3CyXeKbOcVujTo4tkr1W7OcZZY3I2mHZXORe0QxLn1OTXNrM57iGmY+cqtaMZD8S6bPFH/pERL1CK1I4cr7Ix2PrRn6OZGbCWXutRqywaPiY3S++YKoQ4m2Ggl2IRFCwC5EICnYhEkHBLkQiKNiFSISuSm/uhlYrLEHUa3xttpH14fW6tu0IF+oDgMlTXOKZmOC2/vASWgCAwaHwcE2e4ZLRyFVccukd4NLK5BkuodQja8vdfd07gu03rOdpdN848Cy1IcdlrcMH+XGvHw1ngHlE8mo0+L2nGskebEZsuVJYgh3dFiksOsNl28opXhi1r85tk5VIUUwShrUFHhOFUvj88IisrDu7EImgYBciERTsQiSCgl2IRFCwC5EIXZ2NL+Sy2LJ2TdB26MQY7TdPanS9uJ8WtUW9wmdUe0p8JvbYET7DPDQSnpluVPmsacvCSgIAjJ3g/Xr6+Cx4ZYEnY9y16YZg+/vveRftM13lSzIdOHKM2u6/6SZqe+HEa8F26+VKSKPMx+qqzSPUdvQ1fu5s7A2fb5sKXCWZy0Y+l0GeNHT23BS15Xt40lajHh6TgX5e027YwracKRFGiORRsAuRCAp2IRJBwS5EIijYhUgEBbsQibCU5Z8eA/DrAMbd/dZO22cAfAzAmc7bPuXu3190Z9kshtcOBm1ry9O03+RY+OF+b3F5aiBSg25+fp7acqTeHQBU5sL7K/PNodLkxvkp3m/DxgFqq1e4jHOoPBts7/3Z87TP+6/hEtoN+XXUdtO126ht15++HGyfODNH+7zrztupbevWDdRWIdIsAExPhGW0M2M8iapamqK2OpHJAKCe51lUGzZx/33uFDHQLsiVhoLtZqdpn6Xc2f8cwAOB9s+5+x2df4sGuhBidVk02N39RwAmuuCLEGIFuZzf7B83s31m9piZRbLAhRBXApca7F8AcD2AOwCcAvBZ9kYz22Vme8xsT63OH/MUQqwslxTs7j7m7k13bwH4IoC7I+/d7e473X1nId/VR/GFEBdwScFuZqMX/PkhAAeWxx0hxEqxFOntKwDuA7DOzI4D+DSA+8zsDrTFgaMAfm8pO2t6E3ONmaCtfzAsyQHA3FxYTpqf5jJIqcgzhtau45Ld+BmeAbZ2OGyrV7lGcmaCb68VycybOcePLWPhpZUA4J3/+reD7XOnT9A+c6fDGWoAMDM3SW1nj/FtfvI3Pxhs//tf7KN9+jZfR22bhtdTW3kHl21PvHEw2D5xgshdACp9/PO0PD936rP8s371GJfEZsrhMd44FM7YA4Ch7dcE27P5w7TPosHu7h8JNH9psX5CiCsLPUEnRCIo2IVIBAW7EImgYBciERTsQiRCV59yqdYaeO1I+DH7epMv4dPbF5bRNmzmRQMrZf603sw8l7xiz/0cOR7ut26AXzNv2cCzq+bBM8rqdS7jFIu86OHtd/6LYHuzzDPKWvv3UNtT3+OS0ckTL1Hbh3/rt4LtsxM86+1bL4Qz5QDgfb97B7XFPrQakUWvNr4cU/6lF6htoMjPuZxx25RxH6dLYYmtUeASa33ybLDdm/y8151diERQsAuRCAp2IRJBwS5EIijYhUgEBbsQiWDukap2y0whn/eN68JFbfJ5LocVSuH1q+rG5anmPLeNbOOSRq7GCz3+2mw44+mhMydpnyc2bKW2HwzwTD9r8qy3Glcp8e77fiXY/h/edz/t0zh8iNqe3vsTajs1zo/73ptvDbafneZZdK1sJBuxxMeqeo6v9TawfWuw/cYGP99+o5cXh8yDD75H1nPzSmQ9wOPhNQvLJ3lm3huv/SLY/puvHMOLC5VgwOjOLkQiKNiFSAQFuxCJoGAXIhEU7EIkQlcTYbI5x+BQeDZzaJDPgp84E37ovzIbnqUHgOk5bts5PExtn77+Zmq75Z1bgu2ZcT7DfOQwr8X5zchSQhZJDMo4P7af/E14cZ47N/HxtdNvUNutN2+itt94KFSxrM0swjPro+DHvPt//wm1bdi+g9rWkHpsADDq4Rny23p5jULfwZe1qt3EE4oy77iF2rBvLzW1nvxhsD0/foz22VELJ7yUIuqa7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhKUs/7QFwF8A2Ij2ck+73f3zZjYM4GsAtqK9BNRD7s41KAA5GNZnw5JHeWKB9ivNheWEgV5+rXq4j0tNf1DhtcLWnArLfABQORFOWMgdOUr7/FqZS00n1hSp7duRJJkp47JcJReWvJ77u3+kfdYZT0B5zxmeFJI7zZNk+s+dCbeXeULI7x7kp8/Iyz+ltjUlntTSPx2ueZd3PoZW5UlUtolLkXYDl21b/bxuYHYuvHxVZoqPh/eMhg2Z8LgDS7uzNwB80t1vBnAPgN83s5sBPALgKXe/AcBTnb+FEFcoiwa7u59y9+c7r2cBHASwGcCDAB7vvO1xAB9cIR+FEMvARf1mN7OtAO4E8HMAG939fMLtabS/5gshrlCWHOxm1g/gWwA+4e5vWnfZ2xUwgj+szWyXme0xsz31Jv9tJYRYWZYU7GaWRzvQv+zu3+40j5nZaMc+CiA4e+Xuu919p7vvzGc1+S/EarFo9JmZob0e+0F3f/QC0xMAHu68fhjAd5ffPSHEcrFoDTozuxfAPwLYD+D89/BPof27/esArgHwOtrSW3htpw4bhkr+7+4LZyj1D0fqsZGlcza+xmuPfewN/pMhu207teWu5fKJ/exnwXZ/4yDvAy6vocWX6jkzHF4SCADODYxQ21whnBF3XbGf9hlew7dnPVyWswJXbr03vL/sIPcju577gV4upXovrynYyoWl3maDy2utDM8qzA3zJbuyGT5WyPMsuxbZnT/9NN/eD/422Pwvj76C58oLwS0uqrO7+48BsKMPVzcUQlxx6Ee0EImgYBciERTsQiSCgl2IRFCwC5EIXS04mc/ncDWRV/J5Lls0W2F58P5D87RPYYBLJJk1kSd79z9PTXbmRLj91nfzPnfwAoXYspmaNg+Fl8kCgM1FLuOgEs6ya53lMiVIhhoANElhQwDI9HAZzVphaas5x7Mb/TBfTsoL/L7kxn30atjm1TLvE5HeapHCqNkSl0uxltuaV4fP1ex2Xvgy+9HfDhs+/z9pH93ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQhdld5ymQyGe/uCtmKOF4HsHZsJtl8/FykMOHea2prHv0dtC5u4LJe58R1hw4030D5Yx6WazNgRamv9gkuA2alZamtWK8H2Q85lykEiTwHAcDm8PQAo1nhmYasYPrWszgs9os79sALPHmwhUjyS7C+TjWTsRbaHSLHPJh8qWKSoZ6kUllKPN/l4zJPbdOXsOdpHd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhG6OhvvLUe9Gk7UqFX5LOeOl8NJHCXnM5yNBl9mqAE+y1maCi/FAwC9Z6eC7f7Ms7SPt7gf9cgSRPVIbUCLXKMtG07i2Jrlakc+w0+DrEeSTJzPxmcQ/mxifSxiQ4uPVaTyG+Dh8ciQ5Kp2n8jYW+z+yG31yAz/oyTx5iuRXc0QF483IolLfHNCiLcTCnYhEkHBLkQiKNiFSAQFuxCJoGAXIhEWld7MbAuAv0B7SWYHsNvdP29mnwHwMQDnC5h9yt2/H9tWNpfF0HC4Bl1jmksTo0fDclhtIZwgAwCxZa2yEdWlUuH12H6SD8tX85t5vTirceltdJZnTmyf4zajC/QAaITHMR+RZGI0iXTV9oPjzBrpFFvjN76vGBe/cnAzsjOLJMIUIp78ZWSprM8Ohpev2vEOvkzZlmLYyXPPvET7LEVnbwD4pLs/b2YDAJ4zsyc7ts+5+/9YwjaEEKvMUtZ6OwXgVOf1rJkdBMDLogohrkgu6je7mW0FcCfaK7gCwMfNbJ+ZPWZm/LusEGLVWXKwm1k/gG8B+IS7zwD4AoDrAdyB9p3/s6TfLjPbY2Z7Zhd4sQkhxMqypGA3szzagf5ld/82ALj7mLs3vf2w8xcB3B3q6+673X2nu+8c6I0sbiCEWFEWDXYzMwBfAnDQ3R+9oH30grd9CMCB5XdPCLFcLGU2/j0AfgfAfjPb22n7FICPmNkdaCsfRwH83mIbymQyKJXCMkPup1wyGJqaCrZXI1JHTJ6qGbf9YS+vdbZ3y4Zg+zU37aB91m/aSm1nX32R2rb/mGfS/edIzbgsOe5W5Loek64iQ4WmXfz4Z6I6WWx7nNg2nRxA9Jgje8u1uJQ3HRmPr+V5qG0bDdc9fOjf/nvap68vfJ7uf/XRYDuwtNn4HyM81lFNXQhxZaEn6IRIBAW7EImgYBciERTsQiSCgl2IROh6wcnaQlg2eudrPIMtVww/jGPlcPHKNjw76QeFHmr74TB/6ve2df3B9gLmaJ+Rfr6vykh4ewDwvS3rqe3uI+ECnADwXlJIMbKgEQqRDMFYzlg20u9ShL6Yj5Hku0sitrlYActj1w5T2xtlnuF4IjKQt5Elwl45+jLtM7J2MNherfOnVHVnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCJ0VXpDJodsb1i6ePZdPHPMXgnLDKVfvkL7DDa5gLI3w0WeHF8SDSUiAV7T10f71M6+xrfnXLIbXLOG2v6hdI7a7p8LH1susq5cLAPs0k+Q8FYveV+XqL35IuUoQ1ikT0+Fy70nnd87M0WeTTlCMi1b80don1olLOl6nRcq1Z1diERQsAuRCAp2IRJBwS5EIijYhUgEBbsQidBV6c0MKBTC6T9jV4czfwDgGyfDstHzG7jk1ZjmEsQvm1yGsha//hUGwrLhpg3hgoHt7S1Q2+vzvLR2rVqmtrPOP7bJ0bBkN7HjFton3+QFLHMRySvTjKynx2yxCpaxHLtWRDrMXPxKcC2yJh4AZCL3wN5Z/nnWjh+iNuvjUnCDFLHcNrSJ9mk1wxl2uUxE/qMWIcTbCgW7EImgYBciERTsQiSCgl2IRFh0Nt7MSgB+BKDYef833f3TZnYdgK8CGAHwHIDfcffoMq3ZTBZ9feEZ7WKJzwj/Qyl8TfpZZBZ5LsNndnORCmQDM7wWXr4nXJ9u9Jb7aJ/5c2epbfzY09Q2V+Wzxc81uNLwZ5XwrO+xsydpn2xkMruQ4bPIBeO2Fpkhz2Z5H4vO1EeWhoooBmwpJ8vy+1x06bBBrqC8kuP9PCI0zDbDYVjr5TUKS0Viy3H/lnJnrwK4391vR3t55gfM7B4Afwzgc+6+HcAkgI8uYVtCiFVi0WD3NudzMfOdfw7gfgDf7LQ/DuCDK+GgEGJ5WOr67NnOCq7jAJ4E8BqAKXc//z36OIDNK+KhEGJZWFKwu3vT3e8AcDWAuwHwShNvwcx2mdkeM9szPcefChNCrCwXNRvv7lMAngbwbgBDZnZ+ZuFqACdIn93uvtPdd66JLJgghFhZFg12M1tvZkOd1z0AfhXAQbSD/vxq8Q8D+O4K+SiEWAaWkggzCuBxM8uifXH4urv/tZm9BOCrZvbfAPwCwJcW21C+UMBVV4d/2nueSwbvKYdrtd04uoH2ma9wearV5DrI0TFe3+3Agf3B9h033kX79Pdx+eT0+BS1TU9MUFu1h0s8f5YJq5+ZY7ye2WyFK6b1eixhJCI1sfZISTgzboxVkosJduxuFsudKUQktKF+nrA1TpJTAKA+ySXd8YnZcB/j+9p27Z3B9kLhCdpn0WB3930A/smW3f0w2r/fhRD/DNATdEIkgoJdiERQsAuRCAp2IRJBwS5EIpjHtJDl3pnZGQCvd/5cB4CnhHUP+fFm5Meb+efmx7Xuvj5k6Gqwv2nHZnvcfeeq7Fx+yI8E/dDXeCESQcEuRCKsZrDvXsV9X4j8eDPy4828bfxYtd/sQojuoq/xQiTCqgS7mT1gZq+Y2SEze2Q1fOj4cdTM9pvZXjPb08X9PmZm42Z24IK2YTN70sx+2fk/XN1y5f34jJmd6IzJXjP7QBf82GJmT5vZS2b2opn9p057V8ck4kdXx8TMSmb2jJm90PHjDzvt15nZzztx8zUz46miIdy9q/8AZNEua7UNQAHACwBu7rYfHV+OAli3Cvt9L4C7ABy4oO2/A3ik8/oRAH+8Sn58BsAfdHk8RgHc1Xk9AOBVADd3e0wifnR1TNDO2u3vvM4D+DmAewB8HcCHO+3/F8B/vJjtrsad/W4Ah9z9sLdLT38VwIOr4Meq4e4/AvDWhPUH0S7cCXSpgCfxo+u4+yl3f77zehbt4iib0eUxifjRVbzNshd5XY1g3wzg2AV/r2axSgfwQzN7zsx2rZIP59no7qc6r08D4EvDrjwfN7N9na/5K/5z4kLMbCva9RN+jlUck7f4AXR5TFaiyGvqE3T3uvtdAP4NgN83s/eutkNA+8qOeHGWleQLAK5He42AUwA+260dm1k/gG8B+IS7v6m0SzfHJOBH18fEL6PIK2M1gv0EgC0X/E2LVa407n6i8/84gO9gdSvvjJnZKAB0/h9fDSfcfaxzorUAfBFdGhMzy6MdYF929293mrs+JiE/VmtMOvuewkUWeWWsRrA/C+CGzsxiAcCHAfDCWSuEmfWZtYt8mVkfgPcDOBDvtaI8gXbhTmAVC3ieD64OH0IXxsTa6z59CcBBd3/0AlNXx4T50e0xWbEir92aYXzLbOMH0J7pfA3Af1klH7ahrQS8AODFbvoB4Ctofx2so/3b66Nor5n3FIBfAvhbAMOr5MdfAtgPYB/awTbaBT/uRfsr+j4Aezv/PtDtMYn40dUxAXAb2kVc96F9YfmvF5yzzwA4BOAbAIoXs109QSdEIqQ+QSdEMijYhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQgKdiES4f8BN0FTI17WsRIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_t.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e7b8336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ce8f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3,-1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dedcd59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3,-1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db44de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                            (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                            (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b141b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_t, _ = transformed_cifar10[99]\n",
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e4e3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0 , 2:1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "         for img, label in transformed_cifar10\n",
    "         if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "             for img, label in cifar10_val\n",
    "             if label in [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5958ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "n_out = 2\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512,),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, n_out,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bcaeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97767842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61dcfd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0bdff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d24fec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=0)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                 [1.0, 2.0, 3.0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab9dfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d810658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a43831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8b8102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5570, 0.4430]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffb772c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "495bb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fded1e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6357, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img.view(-1).unsqueeze(0))\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62ccaea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 4.500569\n",
      "Epoch: 1, Loss: 6.599077\n",
      "Epoch: 2, Loss: 14.365779\n",
      "Epoch: 3, Loss: 6.454042\n",
      "Epoch: 4, Loss: 8.454642\n",
      "Epoch: 5, Loss: 8.093604\n",
      "Epoch: 6, Loss: 10.932810\n",
      "Epoch: 7, Loss: 5.069043\n",
      "Epoch: 8, Loss: 11.885922\n",
      "Epoch: 9, Loss: 5.853361\n",
      "Epoch: 10, Loss: 12.895825\n",
      "Epoch: 11, Loss: 9.483115\n",
      "Epoch: 12, Loss: 8.191728\n",
      "Epoch: 13, Loss: 0.740299\n",
      "Epoch: 14, Loss: 9.976281\n",
      "Epoch: 15, Loss: 4.719825\n",
      "Epoch: 16, Loss: 11.917905\n",
      "Epoch: 17, Loss: 3.154021\n",
      "Epoch: 18, Loss: 6.240066\n",
      "Epoch: 19, Loss: 3.549754\n",
      "Epoch: 20, Loss: 11.985615\n",
      "Epoch: 21, Loss: 14.139756\n",
      "Epoch: 22, Loss: 8.190253\n",
      "Epoch: 23, Loss: 2.379422\n",
      "Epoch: 24, Loss: 3.209767\n",
      "Epoch: 25, Loss: 6.760672\n",
      "Epoch: 26, Loss: 4.377545\n",
      "Epoch: 27, Loss: 3.784705\n",
      "Epoch: 28, Loss: 16.269840\n",
      "Epoch: 29, Loss: 13.960799\n",
      "Epoch: 30, Loss: 10.586180\n",
      "Epoch: 31, Loss: 8.443891\n",
      "Epoch: 32, Loss: 11.003699\n",
      "Epoch: 33, Loss: 2.748264\n",
      "Epoch: 34, Loss: 12.971228\n",
      "Epoch: 35, Loss: 9.464051\n",
      "Epoch: 36, Loss: 14.117583\n",
      "Epoch: 37, Loss: 4.700507\n",
      "Epoch: 38, Loss: 8.486345\n",
      "Epoch: 39, Loss: 8.604299\n",
      "Epoch: 40, Loss: 4.078646\n",
      "Epoch: 41, Loss: 0.014130\n",
      "Epoch: 42, Loss: 3.371951\n",
      "Epoch: 43, Loss: 0.761517\n",
      "Epoch: 44, Loss: 6.381145\n",
      "Epoch: 45, Loss: 3.869298\n",
      "Epoch: 46, Loss: 0.812782\n",
      "Epoch: 47, Loss: 6.095400\n",
      "Epoch: 48, Loss: 6.136667\n",
      "Epoch: 49, Loss: 0.012220\n",
      "Epoch: 50, Loss: 5.794330\n",
      "Epoch: 51, Loss: 13.610385\n",
      "Epoch: 52, Loss: 5.090464\n",
      "Epoch: 53, Loss: 3.916996\n",
      "Epoch: 54, Loss: 17.699408\n",
      "Epoch: 55, Loss: 11.642148\n",
      "Epoch: 56, Loss: 2.962079\n",
      "Epoch: 57, Loss: 6.646529\n",
      "Epoch: 58, Loss: 0.000309\n",
      "Epoch: 59, Loss: 10.884590\n",
      "Epoch: 60, Loss: 3.472079\n",
      "Epoch: 61, Loss: 4.038675\n",
      "Epoch: 62, Loss: 2.602446\n",
      "Epoch: 63, Loss: 6.060660\n",
      "Epoch: 64, Loss: 12.793305\n",
      "Epoch: 65, Loss: 18.158867\n",
      "Epoch: 66, Loss: 0.301845\n",
      "Epoch: 67, Loss: 8.048378\n",
      "Epoch: 68, Loss: 8.647563\n",
      "Epoch: 69, Loss: 9.472447\n",
      "Epoch: 70, Loss: 13.771451\n",
      "Epoch: 71, Loss: 8.986944\n",
      "Epoch: 72, Loss: 7.279968\n",
      "Epoch: 73, Loss: 2.430853\n",
      "Epoch: 74, Loss: 9.436108\n",
      "Epoch: 75, Loss: 14.806246\n",
      "Epoch: 76, Loss: 5.509427\n",
      "Epoch: 77, Loss: 10.513478\n",
      "Epoch: 78, Loss: 9.820966\n",
      "Epoch: 79, Loss: 23.911427\n",
      "Epoch: 80, Loss: 16.054520\n",
      "Epoch: 81, Loss: 14.685600\n",
      "Epoch: 82, Loss: 20.257030\n",
      "Epoch: 83, Loss: 13.848527\n",
      "Epoch: 84, Loss: 19.508112\n",
      "Epoch: 85, Loss: 14.575720\n",
      "Epoch: 86, Loss: 15.563707\n",
      "Epoch: 87, Loss: 14.941271\n",
      "Epoch: 88, Loss: 0.619565\n",
      "Epoch: 89, Loss: 14.678860\n",
      "Epoch: 90, Loss: 0.358507\n",
      "Epoch: 91, Loss: 11.163415\n",
      "Epoch: 92, Loss: 3.377077\n",
      "Epoch: 93, Loss: 12.945395\n",
      "Epoch: 94, Loss: 0.055907\n",
      "Epoch: 95, Loss: 6.686927\n",
      "Epoch: 96, Loss: 2.326377\n",
      "Epoch: 97, Loss: 4.778745\n",
      "Epoch: 98, Loss: 7.168054\n",
      "Epoch: 99, Loss: 3.529076\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "model = nn.Sequential(nn.Linear(3072, 512),\n",
    "                     nn.Tanh(),\n",
    "                     nn.Linear(512,2),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a0416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f1fd296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3072, out_features=512, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11bc32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Save_File_FM.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "700d5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "model = torch.load('Save_File_FM.pth')\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "389c453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.502599\n",
      "Epoch: 1, Loss: 0.509853\n",
      "Epoch: 2, Loss: 0.431800\n",
      "Epoch: 3, Loss: 0.489269\n",
      "Epoch: 4, Loss: 0.313390\n",
      "Epoch: 5, Loss: 0.410486\n",
      "Epoch: 6, Loss: 0.410222\n",
      "Epoch: 7, Loss: 0.325822\n",
      "Epoch: 8, Loss: 0.496187\n",
      "Epoch: 9, Loss: 0.662401\n",
      "Epoch: 10, Loss: 0.332874\n",
      "Epoch: 11, Loss: 0.272162\n",
      "Epoch: 12, Loss: 0.655266\n",
      "Epoch: 13, Loss: 0.364622\n",
      "Epoch: 14, Loss: 0.315125\n",
      "Epoch: 15, Loss: 0.527363\n",
      "Epoch: 16, Loss: 0.488687\n",
      "Epoch: 17, Loss: 0.455992\n",
      "Epoch: 18, Loss: 0.270281\n",
      "Epoch: 19, Loss: 0.388717\n",
      "Epoch: 20, Loss: 0.153037\n",
      "Epoch: 21, Loss: 0.289861\n",
      "Epoch: 22, Loss: 0.307466\n",
      "Epoch: 23, Loss: 0.439243\n",
      "Epoch: 24, Loss: 0.179587\n",
      "Epoch: 25, Loss: 0.254773\n",
      "Epoch: 26, Loss: 0.300128\n",
      "Epoch: 27, Loss: 0.352430\n",
      "Epoch: 28, Loss: 0.254564\n",
      "Epoch: 29, Loss: 0.235600\n",
      "Epoch: 30, Loss: 0.156204\n",
      "Epoch: 31, Loss: 0.211157\n",
      "Epoch: 32, Loss: 0.150680\n",
      "Epoch: 33, Loss: 0.395550\n",
      "Epoch: 34, Loss: 0.136442\n",
      "Epoch: 35, Loss: 0.157952\n",
      "Epoch: 36, Loss: 0.321628\n",
      "Epoch: 37, Loss: 0.483971\n",
      "Epoch: 38, Loss: 0.127646\n",
      "Epoch: 39, Loss: 0.019826\n",
      "Epoch: 40, Loss: 0.259050\n",
      "Epoch: 41, Loss: 0.156407\n",
      "Epoch: 42, Loss: 0.099386\n",
      "Epoch: 43, Loss: 0.073063\n",
      "Epoch: 44, Loss: 0.069408\n",
      "Epoch: 45, Loss: 0.093933\n",
      "Epoch: 46, Loss: 0.064033\n",
      "Epoch: 47, Loss: 0.194791\n",
      "Epoch: 48, Loss: 0.099277\n",
      "Epoch: 49, Loss: 0.014939\n",
      "Epoch: 50, Loss: 0.021610\n",
      "Epoch: 51, Loss: 0.046048\n",
      "Epoch: 52, Loss: 0.098672\n",
      "Epoch: 53, Loss: 0.000692\n",
      "Epoch: 54, Loss: 0.025369\n",
      "Epoch: 55, Loss: 0.056471\n",
      "Epoch: 56, Loss: 0.011269\n",
      "Epoch: 57, Loss: 0.004290\n",
      "Epoch: 58, Loss: 0.122010\n",
      "Epoch: 59, Loss: 0.011895\n",
      "Epoch: 60, Loss: 0.003849\n",
      "Epoch: 61, Loss: 0.001117\n",
      "Epoch: 62, Loss: 0.017314\n",
      "Epoch: 63, Loss: 0.012421\n",
      "Epoch: 64, Loss: 0.022264\n",
      "Epoch: 65, Loss: 0.003721\n",
      "Epoch: 66, Loss: 0.007817\n",
      "Epoch: 67, Loss: 2.739416\n",
      "Epoch: 68, Loss: 0.003290\n",
      "Epoch: 69, Loss: 0.003589\n",
      "Epoch: 70, Loss: 0.024891\n",
      "Epoch: 71, Loss: 0.001663\n",
      "Epoch: 72, Loss: 0.022128\n",
      "Epoch: 73, Loss: 0.011225\n",
      "Epoch: 74, Loss: 0.001793\n",
      "Epoch: 75, Loss: 0.008141\n",
      "Epoch: 76, Loss: 0.020743\n",
      "Epoch: 77, Loss: 0.011861\n",
      "Epoch: 78, Loss: 0.002964\n",
      "Epoch: 79, Loss: 0.002380\n",
      "Epoch: 80, Loss: 0.053443\n",
      "Epoch: 81, Loss: 0.002253\n",
      "Epoch: 82, Loss: 0.002373\n",
      "Epoch: 83, Loss: 0.003009\n",
      "Epoch: 84, Loss: 0.011952\n",
      "Epoch: 85, Loss: 0.002098\n",
      "Epoch: 86, Loss: 0.002579\n",
      "Epoch: 87, Loss: 0.005400\n",
      "Epoch: 88, Loss: 0.006744\n",
      "Epoch: 89, Loss: 0.003151\n",
      "Epoch: 90, Loss: 0.003686\n",
      "Epoch: 91, Loss: 0.000870\n",
      "Epoch: 92, Loss: 0.001418\n",
      "Epoch: 93, Loss: 0.000388\n",
      "Epoch: 94, Loss: 0.002761\n",
      "Epoch: 95, Loss: 0.002133\n",
      "Epoch: 96, Loss: 0.002492\n",
      "Epoch: 97, Loss: 0.002365\n",
      "Epoch: 98, Loss: 0.003642\n",
      "Epoch: 99, Loss: 0.003172\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle= True)\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbfd35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.814500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size, shuffle = False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim =1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "743ca1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Save_File_FM.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65755e88",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fc3c5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(3072, 1024),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(512, 128),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(128,2),\n",
    "                    nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e689361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(3072, 1024),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(512, 128),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(128,2),)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5cc37b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "81fbe765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574402, [1572864, 512, 1024, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "31b1a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b0da05f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =torch.tensor()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "71890774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x4 and 3072x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8388\\801350638.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLinear_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\DeepLearn-eMPOc9HF\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x4 and 3072x512)"
     ]
    }
   ],
   "source": [
    "Linear_model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
